{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1aca9-62fc-4465-a7d4-f5d20565e12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:18:00.848663Z",
     "iopub.status.busy": "2024-07-10T15:18:00.848264Z",
     "iopub.status.idle": "2024-07-10T15:18:06.384875Z",
     "shell.execute_reply": "2024-07-10T15:18:06.384016Z",
     "shell.execute_reply.started": "2024-07-10T15:18:00.848641Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449690ee-e39b-4efd-bac5-12c9691f6118",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:18:23.993067Z",
     "iopub.status.busy": "2024-07-10T15:18:23.992721Z",
     "iopub.status.idle": "2024-07-10T15:18:27.349855Z",
     "shell.execute_reply": "2024-07-10T15:18:27.349011Z",
     "shell.execute_reply.started": "2024-07-10T15:18:23.993045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torchtext contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8227cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04ecd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:22:30.732903Z",
     "start_time": "2024-05-14T02:22:30.719902Z"
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:18:30.096485Z",
     "iopub.status.busy": "2024-07-10T15:18:30.096126Z",
     "iopub.status.idle": "2024-07-10T15:18:30.471914Z",
     "shell.execute_reply": "2024-07-10T15:18:30.471204Z",
     "shell.execute_reply.started": "2024-07-10T15:18:30.096464Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import contractions\n",
    "from timeit import default_timer as timer\n",
    "import re\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54b760a5c01756",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd9ea952151dec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:50.975889Z",
     "start_time": "2024-05-14T02:19:49.091451Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:22:08.546161Z",
     "iopub.status.busy": "2024-07-10T15:22:08.545805Z",
     "iopub.status.idle": "2024-07-10T15:22:08.550406Z",
     "shell.execute_reply": "2024-07-10T15:22:08.549706Z",
     "shell.execute_reply.started": "2024-07-10T15:22:08.546142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载对应的tokenizer\n",
    "# 源语言是英语\n",
    "SRC_LANGUAGE = 'en'\n",
    "# 目标语言是中文\n",
    "TGT_LANGUAGE = 'zh'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2ea0f9fe9f9fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:50.991925Z",
     "start_time": "2024-05-14T02:19:50.978893Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:18.858289Z",
     "iopub.status.busy": "2024-07-10T15:24:18.857946Z",
     "iopub.status.idle": "2024-07-10T15:24:18.861623Z",
     "shell.execute_reply": "2024-07-10T15:24:18.860902Z",
     "shell.execute_reply.started": "2024-07-10T15:24:18.858253Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0b61408b79b3f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:51.007119Z",
     "start_time": "2024-05-14T02:19:50.993892Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:19.186228Z",
     "iopub.status.busy": "2024-07-10T15:24:19.185915Z",
     "iopub.status.idle": "2024-07-10T15:24:19.189651Z",
     "shell.execute_reply": "2024-07-10T15:24:19.188917Z",
     "shell.execute_reply.started": "2024-07-10T15:24:19.186209Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_iterator(src_data, tgt_data):\n",
    "    \"\"\"\n",
    "    src_data: [en]\n",
    "    tgt_data: [zh]\n",
    "    \"\"\"\n",
    "    # 将传入的数据以数据对的形式返回\n",
    "    # [(de, en), (de, en)]\n",
    "    return [(src_line.strip(), tgt_line.strip()) for src_line, tgt_line in zip(src_data, tgt_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcc7c89010e4888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:51.023105Z",
     "start_time": "2024-05-14T02:19:51.010894Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:19.665994Z",
     "iopub.status.busy": "2024-07-10T15:24:19.665600Z",
     "iopub.status.idle": "2024-07-10T15:24:19.669713Z",
     "shell.execute_reply": "2024-07-10T15:24:19.668994Z",
     "shell.execute_reply.started": "2024-07-10T15:24:19.665974Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        # 获取对应语言的分词器,并用来对对应部分的句子做分词\n",
    "        yield token_transform[language](data_sample[language_index[language]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34d7b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:22.546332Z",
     "iopub.status.busy": "2024-07-10T15:24:22.545940Z",
     "iopub.status.idle": "2024-07-10T15:24:22.551405Z",
     "shell.execute_reply": "2024-07-10T15:24:22.550407Z",
     "shell.execute_reply.started": "2024-07-10T15:24:22.546309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 字符规范化函数\n",
    "def unicodeToAscii(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# 英文数据预处理函数\n",
    "def preprocess_en(text):\n",
    "    text = unicodeToAscii(text.strip())\n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r'\\（[^）]*\\）', '', text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", text)  # 保留数字\n",
    "    return text\n",
    "\n",
    "# 中文数据预处理函数\n",
    "def preprocess_zh(text):\n",
    "    # 去除(掌声)这些脏数据\n",
    "    text = re.sub(r'\\（[^）]*\\）', '', text)\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fa5，。！？0-9a-zA-Z]\", \"\", text)  # 保留数字和英文字母\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae49baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.849 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/en-zh.dic', 'r', encoding='utf-8') as f:\n",
    "    dic = [line.strip().split('\\t') for line in f.readlines()]\n",
    "    dic_en_zh = {key: value for key, value in dic}\n",
    "    dic_zh_en = {value: key for key, value in dic}\n",
    "    \n",
    "\n",
    "# 将每个词添加进jieba的分词表中\n",
    "for key, value in dic_en_zh.items():\n",
    "    jieba.add_word(key)\n",
    "    jieba.add_word(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train.txt\", \"a+\", encoding='utf-8') as f:\n",
    "    for en, zh in dic:\n",
    "        f.write(f\"{en}\\t{zh}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db49376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_split_symbols(tokens, special_dict):\n",
    "    return ['<|sword|>' + token + '<|eword|>' if token in special_dict else token for token in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f702cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义词表\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = lambda x: add_split_symbols(x.split(' '), dic_en_zh)\n",
    "token_transform[TGT_LANGUAGE] = lambda x: list(jieba.cut(x))\n",
    "\n",
    "# 你可能还需要构建词表（vocabulary），这里省略了相关代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a823a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:23.720853Z",
     "iopub.status.busy": "2024-07-10T15:24:23.720487Z",
     "iopub.status.idle": "2024-07-10T15:24:28.242931Z",
     "shell.execute_reply": "2024-07-10T15:24:28.242419Z",
     "shell.execute_reply.started": "2024-07-10T15:24:23.720832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./data/train.txt\", 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "    en_data = [preprocess_en(line.strip().split('\\t')[0]) for line in data]\n",
    "    zh_data = [preprocess_zh(line.strip().split('\\t')[1]) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33ff2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oxford',\n",
       " 'philosopher',\n",
       " 'and',\n",
       " 'transhumanist',\n",
       " '<|sword|>Nick<|eword|>',\n",
       " 'Bostrom',\n",
       " 'examines',\n",
       " 'the',\n",
       " '<|sword|>future<|eword|>',\n",
       " 'of',\n",
       " 'humankind',\n",
       " 'and',\n",
       " 'asks',\n",
       " 'whether',\n",
       " 'we',\n",
       " 'might',\n",
       " 'alter',\n",
       " 'the',\n",
       " 'fundamental',\n",
       " 'nature',\n",
       " 'of',\n",
       " '<|sword|>humanity<|eword|>',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'our',\n",
       " 'most',\n",
       " 'intrinsic',\n",
       " 'problems.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试自定义的分词和添加特殊符号功能\n",
    "test_sentence_en = \"Oxford philosopher and transhumanist Nick Bostrom examines the future of humankind and asks whether we might alter the fundamental nature of humanity to solve our most intrinsic problems.\"\n",
    "token_transform[SRC_LANGUAGE](test_sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98b8d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data[len(en_data)-len(dic)]\n",
    "en_data_ = []\n",
    "for i in range(len(en_data)):\n",
    "    if i < len(en_data)-len(dic):\n",
    "        en_data_.append(en_data[i])\n",
    "    else:\n",
    "        en_data_.append('<|sword|>'+en_data[i]+'<|eword|>')\n",
    "\n",
    "en_data = en_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1a27ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:29.883111Z",
     "iopub.status.busy": "2024-07-10T15:24:29.882741Z",
     "iopub.status.idle": "2024-07-10T15:24:29.981384Z",
     "shell.execute_reply": "2024-07-10T15:24:29.980836Z",
     "shell.execute_reply.started": "2024-07-10T15:24:29.883090Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./data/train.en', 'w', encoding='utf-8') as f:\n",
    "    for line in en_data:\n",
    "        f.write(line+\"\\n\")\n",
    "        \n",
    "with open('./data/train.zh', 'w', encoding='utf-8') as f:\n",
    "    for line in zh_data:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488aa808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50ca7380fa99e0c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:51.070662Z",
     "start_time": "2024-05-14T02:19:51.024625Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:30.869063Z",
     "iopub.status.busy": "2024-07-10T15:24:30.868638Z",
     "iopub.status.idle": "2024-07-10T15:24:31.027076Z",
     "shell.execute_reply": "2024-07-10T15:24:31.026444Z",
     "shell.execute_reply.started": "2024-07-10T15:24:30.869037Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载训练和验证数据\n",
    "train_src_file = './data/train.en'  \n",
    "train_tgt_file = './data/train.zh'  \n",
    "\n",
    "valid_src_file = './data/dev_en.txt'  \n",
    "valid_tgt_file = './data/dev_zh.txt'  \n",
    "\n",
    "train_src_data = read_data(train_src_file)\n",
    "train_tgt_data = read_data(train_tgt_file)\n",
    "\n",
    "valid_src_data = read_data(valid_src_file)\n",
    "valid_tgt_data = read_data(valid_tgt_file)\n",
    "\n",
    "train_data = data_iterator(train_src_data, train_tgt_data)\n",
    "valid_data = data_iterator(valid_src_data, valid_tgt_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "222e0f06eade186b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.674454Z",
     "start_time": "2024-05-14T02:19:51.089626Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:33.431900Z",
     "iopub.status.busy": "2024-07-10T15:24:33.431533Z",
     "iopub.status.idle": "2024-07-10T15:24:49.460878Z",
     "shell.execute_reply": "2024-07-10T15:24:49.460397Z",
     "shell.execute_reply.started": "2024-07-10T15:24:33.431880Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': Vocab(), 'zh': Vocab()}\n"
     ]
    }
   ],
   "source": [
    "# 定义特殊字符以及它们在词汇表中的索引\n",
    "# UNK_IDX：未知词的索引\n",
    "# PAD_IDX：填充词的索引\n",
    "# BOS_IDX：句子开始符的索引\n",
    "# EOS_IDX：句子结束符的索引\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX, SWORD_IDX, EWORD_IDX = 0, 1, 2, 3, 4, 5\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>', '<|sword|>', \"<|eword|>\"]\n",
    "\n",
    "# 构建 vocab_transform\n",
    "# vocab_transform 是一个字典，用于存储源语言和目标语言的词汇表\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(train_data, ln),  # 从数据迭代器中生成分词结果\n",
    "        min_freq=1,  # 词汇表中的词必须至少出现1次\n",
    "        specials=special_symbols,  # 特殊符号列表\n",
    "        special_first=True  # 将特殊符号放在词汇表的前面\n",
    "    )\n",
    "print(vocab_transform)\n",
    "\n",
    "# 将unk设置为默认字符\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ed4ed399d65cd",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54fa57f9a90984f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.705454Z",
     "start_time": "2024-05-14T02:19:56.678454Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:49.745970Z",
     "iopub.status.busy": "2024-07-10T15:24:49.745634Z",
     "iopub.status.idle": "2024-07-10T15:24:49.751712Z",
     "shell.execute_reply": "2024-07-10T15:24:49.751028Z",
     "shell.execute_reply.started": "2024-07-10T15:24:49.745950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 定义位置编码器\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, max_len).reshape(max_len, 1)\n",
    "        pos_embedding = torch.zeros((max_len, emb_size))\n",
    "        # 填充\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        # 变成三维, 方便后期计算\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        # 将token_embedding和位置编码相融合\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4f855930bebfca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.721453Z",
     "start_time": "2024-05-14T02:19:56.708460Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:50.866166Z",
     "iopub.status.busy": "2024-07-10T15:24:50.865805Z",
     "iopub.status.idle": "2024-07-10T15:24:50.870365Z",
     "shell.execute_reply": "2024-07-10T15:24:50.869676Z",
     "shell.execute_reply.started": "2024-07-10T15:24:50.866145Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        # 调用nn中的预定义层Embedding, 获取一个词嵌入对象self.embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        # 让 embeddings vector 在增加 之后的 position encoding 之前相对大一些的操作，\n",
    "        # 主要是为了让position encoding 相对的小，这样会让原来的 embedding vector 中的信息在和 position encoding 的信息相加时不至于丢失掉\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d79fb286faeebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.753452Z",
     "start_time": "2024-05-14T02:19:56.727452Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:51.588136Z",
     "iopub.status.busy": "2024-07-10T15:24:51.587791Z",
     "iopub.status.idle": "2024-07-10T15:24:51.594027Z",
     "shell.execute_reply": "2024-07-10T15:24:51.593478Z",
     "shell.execute_reply.started": "2024-07-10T15:24:51.588116Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size, nhead, src_vocab_size, tgt_vocab_size, dim_feedforward=512, dropout=0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        # 创建Transformer对象\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        # 创建全连接线性层\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        # 创建源语言的embedding层\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        # 创建目标语言的embedding层\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        # 创建位置编码器层对象\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c0320fba3c23d",
   "metadata": {},
   "source": [
    "# 定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27d44bad363b988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.768453Z",
     "start_time": "2024-05-14T02:19:56.757452Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:53.258425Z",
     "iopub.status.busy": "2024-07-10T15:24:53.258089Z",
     "iopub.status.idle": "2024-07-10T15:24:53.262087Z",
     "shell.execute_reply": "2024-07-10T15:24:53.261503Z",
     "shell.execute_reply.started": "2024-07-10T15:24:53.258406Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 生成一个上三角矩阵掩码，用于目标序列\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    # 生成一个sz x sz的上三角矩阵，值全为1\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    # 将上三角矩阵中的0位置的值替换为负无穷大，将1位置的值替换为0,因为在transform库中的掩码是对0为非遮掩部分\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be51ab24ef718f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.783448Z",
     "start_time": "2024-05-14T02:19:56.771452Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:55.666526Z",
     "iopub.status.busy": "2024-07-10T15:24:55.666138Z",
     "iopub.status.idle": "2024-07-10T15:24:55.671022Z",
     "shell.execute_reply": "2024-07-10T15:24:55.670372Z",
     "shell.execute_reply.started": "2024-07-10T15:24:55.666501Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "    # 生成目标序列的掩码\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    # 源序列的掩码，全为0\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "    # 源序列和目标序列的填充掩码，标记出填充位置\n",
    "    # 这里转置的原因是:\n",
    "    # src和tgt的shape是(seq_len, batch_siez), 通过转置后,我们的src_padding_mask为(batch_size, seq_len)\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05366a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:56.786010Z",
     "iopub.status.busy": "2024-07-10T15:24:56.785672Z",
     "iopub.status.idle": "2024-07-10T15:24:59.317169Z",
     "shell.execute_reply": "2024-07-10T15:24:59.316669Z",
     "shell.execute_reply.started": "2024-07-10T15:24:56.785990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_mask:\n",
      " tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]], device='cuda:0')\n",
      "tgt_mask:\n",
      " tensor([[0., -inf, -inf],\n",
      "        [0., 0., -inf],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "src_padding_mask:\n",
      " tensor([[False, False,  True],\n",
      "        [False, False,  True],\n",
      "        [False,  True,  True]], device='cuda:0')\n",
      "tgt_padding_mask:\n",
      " tensor([[False, False,  True],\n",
      "        [False,  True,  True],\n",
      "        [False,  True,  True]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 示例源序列和目标序列\n",
    "src = torch.tensor([[5, 2, 3], [4, 5, 1], [1, 1, 1]], dtype=torch.long, device=DEVICE)\n",
    "tgt = torch.tensor([[3, 2, 3], [4, 1, 1], [1, 1, 1]], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# 创建掩码\n",
    "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt)\n",
    "\n",
    "print(\"src_mask:\\n\", src_mask)\n",
    "print(\"tgt_mask:\\n\", tgt_mask)\n",
    "print(\"src_padding_mask:\\n\", src_padding_mask)\n",
    "print(\"tgt_padding_mask:\\n\", tgt_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f56efc3407bdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.798456Z",
     "start_time": "2024-05-14T02:19:56.785452Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:24:59.318405Z",
     "iopub.status.busy": "2024-07-10T15:24:59.318098Z",
     "iopub.status.idle": "2024-07-10T15:24:59.321678Z",
     "shell.execute_reply": "2024-07-10T15:24:59.321086Z",
     "shell.execute_reply.started": "2024-07-10T15:24:59.318384Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 将多个转换函数串联起来\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12d6697bc6a90ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.814033Z",
     "start_time": "2024-05-14T02:19:56.800454Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:01.745979Z",
     "iopub.status.busy": "2024-07-10T15:25:01.745638Z",
     "iopub.status.idle": "2024-07-10T15:25:01.749459Z",
     "shell.execute_reply": "2024-07-10T15:25:01.748739Z",
     "shell.execute_reply.started": "2024-07-10T15:25:01.745960Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 将token列表转换为tensor，并添加开始和结束标记\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a6ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "477ee96c0a077b97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.845558Z",
     "start_time": "2024-05-14T02:19:56.816559Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:03.188188Z",
     "iopub.status.busy": "2024-07-10T15:25:03.187807Z",
     "iopub.status.idle": "2024-07-10T15:25:03.192062Z",
     "shell.execute_reply": "2024-07-10T15:25:03.191233Z",
     "shell.execute_reply.started": "2024-07-10T15:25:03.188159Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln],  # 分词\n",
    "                                               vocab_transform[ln],  # 数值化\n",
    "                                               tensor_transform)  # 添加BOS/EOS并转换为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc4100b6a3cc5a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:56.861555Z",
     "start_time": "2024-05-14T02:19:56.847556Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:03.425905Z",
     "iopub.status.busy": "2024-07-10T15:25:03.425558Z",
     "iopub.status.idle": "2024-07-10T15:25:03.429823Z",
     "shell.execute_reply": "2024-07-10T15:25:03.429307Z",
     "shell.execute_reply.started": "2024-07-10T15:25:03.425877Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 数据批处理函数，用于DataLoader\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    [('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
    "  'Two young, White males are outside near many bushes.'),.....]\n",
    "    \"\"\"\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        # 对源语言和目标语言的句子进行转换处理\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "    # 对源语言和目标语言的批次进行填充\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a33784d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:06.863385Z",
     "iopub.status.busy": "2024-07-10T15:25:06.862986Z",
     "iopub.status.idle": "2024-07-10T15:25:06.867242Z",
     "shell.execute_reply": "2024-07-10T15:25:06.866430Z",
     "shell.execute_reply.started": "2024-07-10T15:25:06.863365Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0dfcf",
   "metadata": {},
   "source": [
    "![](./img/imp_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d959ce0ddd28b33f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:19:57.669931Z",
     "start_time": "2024-05-14T02:19:56.864558Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:32.708252Z",
     "iopub.status.busy": "2024-07-10T15:25:32.707926Z",
     "iopub.status.idle": "2024-07-10T15:25:34.997162Z",
     "shell.execute_reply": "2024-07-10T15:25:34.996619Z",
     "shell.execute_reply.started": "2024-07-10T15:25:32.708232Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# 设置种子用于生成随机数，以使得结果是确定的\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 设置调用时候使用的参数\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# 实例化Transformer对象\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "# 为了保证每层的输入和输出的方差相同, 防止梯度消失问题\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "# 如果有GPU则将模型移动到GPU上\n",
    "transformer = transformer.to(DEVICE)\n",
    "# 定义损失函数\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "# 定义优化器  betas: 用于计算梯度及其平方的运行平均值的系数  eps:添加到分母以提高数值稳定性\n",
    "\"\"\"\n",
    "betas 是 Adam 优化器中两个超参数的元组，用于计算一阶和二阶矩估计的指数衰减率。\n",
    "第一个值 0.9 是用于计算梯度的一阶矩（即动量）的衰减率。较高的值表示动量更大，历史梯度的影响更长久。\n",
    "第二个值 0.98 是用于计算梯度的二阶矩（即平方梯度）的衰减率。较高的值表示对最近梯度变化的敏感度更低。\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6608e49413eae30",
   "metadata": {},
   "source": [
    "# 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e458483130440ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:22:48.603437Z",
     "start_time": "2024-05-14T02:22:48.590433Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:36.138971Z",
     "iopub.status.busy": "2024-07-10T15:25:36.138560Z",
     "iopub.status.idle": "2024-07-10T15:25:36.143846Z",
     "shell.execute_reply": "2024-07-10T15:25:36.143149Z",
     "shell.execute_reply.started": "2024-07-10T15:25:36.138950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for src, tgt in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        # 这一步将目标序列的最后一个时间步去掉，得到 tgt_input。这是因为在训练过程中，我们使用目标序列的前 T个时间步。\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        tgt_out = tgt[1:].to(torch.long)\n",
    "        logits = logits.to(torch.float32)\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58488cff7697ae30",
   "metadata": {},
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92d4cecb706b1d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:22:56.631733Z",
     "start_time": "2024-05-14T02:22:56.611733Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-10T15:25:40.948204Z",
     "iopub.status.busy": "2024-07-10T15:25:40.947888Z",
     "iopub.status.idle": "2024-07-10T15:25:40.952410Z",
     "shell.execute_reply": "2024-07-10T15:25:40.951907Z",
     "shell.execute_reply.started": "2024-07-10T15:25:40.948185Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for src, tgt in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "578a74d422fa6493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:24:55.220578Z",
     "start_time": "2024-05-14T02:22:58.183935Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9551 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m      8\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(transformer, valid_dataloader)\n",
      "Cell \u001b[1;32mIn[41], line 14\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, dataloader)\u001b[0m\n\u001b[0;32m     12\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), tgt_out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, valid_dataloader)\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806383c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:40.120809Z",
     "iopub.status.busy": "2024-07-10T15:47:40.120480Z",
     "iopub.status.idle": "2024-07-10T15:47:41.708167Z",
     "shell.execute_reply": "2024-07-10T15:47:41.707571Z",
     "shell.execute_reply.started": "2024-07-10T15:47:40.120790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 模型保存和加载\n",
    "path = './model/transformer_translation_5.pth'\n",
    "torch.save(transformer.state_dict(), path)\n",
    "\n",
    "# 加载模型\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "transformer.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b3c2a36b714d2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T02:20:47.012476Z",
     "start_time": "2024-05-14T02:20:47.011967Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:46.580179Z",
     "iopub.status.busy": "2024-07-10T15:47:46.579860Z",
     "iopub.status.idle": "2024-07-10T15:47:46.586040Z",
     "shell.execute_reply": "2024-07-10T15:47:46.585155Z",
     "shell.execute_reply.started": "2024-07-10T15:47:46.580159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 贪婪解码函数，用于从模型中生成翻译结果\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    # 将输入数据和掩码移动到设备上\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    \n",
    "    # 编码器对源序列进行编码\n",
    "    memory = model.encode(src, src_mask)\n",
    "    \n",
    "    # 初始化目标序列，以开始符号开始\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    \n",
    "    # 逐步生成目标序列\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        \n",
    "        # 生成目标序列掩码\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
    "        # 解码器对目标序列进行解码\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        \n",
    "        # 生成下一个词的概率分布\n",
    "        prob = model.generator(out[:, -1])\n",
    "        \n",
    "        # 选择概率最高的词作为下一个词\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        \n",
    "        # 将下一个词添加到目标序列中\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        \n",
    "        # 如果生成结束符，则停止生成\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    \n",
    "    # 返回生成的目标序列\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6f6c9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:47.219746Z",
     "iopub.status.busy": "2024-07-10T15:47:47.219399Z",
     "iopub.status.idle": "2024-07-10T15:47:47.328244Z",
     "shell.execute_reply": "2024-07-10T15:47:47.327672Z",
     "shell.execute_reply.started": "2024-07-10T15:47:47.219725Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 翻译函数，将源语言句子翻译成目标语言句子\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    \n",
    "    # 将源语言句子进行分词、数值化和tensor转换\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    src = src.to(DEVICE)\n",
    "    # 获取源序列的长度\n",
    "    num_tokens = src.shape[0]\n",
    "    \n",
    "    # 创建源序列掩码，全为0\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    \n",
    "    # 使用贪婪解码生成目标语言句子\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    \n",
    "    # 将生成的目标语言句子tensor转换为字符串，并去掉开始和结束符\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d622d7ab-2a35-4fe1-b03a-ed22c057a609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:49.689804Z",
     "iopub.status.busy": "2024-07-10T15:47:49.689441Z",
     "iopub.status.idle": "2024-07-10T15:47:49.693881Z",
     "shell.execute_reply": "2024-07-10T15:47:49.693209Z",
     "shell.execute_reply.started": "2024-07-10T15:47:49.689781Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./data/test_en.txt\", 'r', encoding='utf-8') as f:\n",
    "    test_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3afa341-a0fb-43b7-bf3b-0d7b82d8e003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:49.999452Z",
     "iopub.status.busy": "2024-07-10T15:47:49.999086Z",
     "iopub.status.idle": "2024-07-10T15:47:50.003346Z",
     "shell.execute_reply": "2024-07-10T15:47:50.002760Z",
     "shell.execute_reply.started": "2024-07-10T15:47:49.999431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The canneries are gone. The pollution has abated.\\n',\n",
       " 'Handspring Puppet Co.: The genius puppetry behind War Horse\\n',\n",
       " 'But now we would like you to put Joey through some paces.\\n',\n",
       " \"And this is exactly what we've been seeing with teenagers and kids doing it in school, under the table, and texting under the table to their friends.\\n\",\n",
       " 'When it was announced that they were going to do every child in Uruguay, the first 100,000, boom, went to OLPC.\\n']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c96b4-2957-4de5-99d8-9987a1a62fd6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-10T15:49:51.412133Z",
     "iopub.status.busy": "2024-07-10T15:49:51.411762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"sumbit.txt\", 'w', encoding='utf-8') as f:\n",
    "    for line in test_data:\n",
    "        transformer.to(DEVICE)\n",
    "        res = translate(transformer, line)\n",
    "        f.write(''.join(res.split(' '))+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f81ea09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T15:47:53.290118Z",
     "iopub.status.busy": "2024-07-10T15:47:53.289755Z",
     "iopub.status.idle": "2024-07-10T15:47:53.424972Z",
     "shell.execute_reply": "2024-07-10T15:47:53.424426Z",
     "shell.execute_reply.started": "2024-07-10T15:47:53.290096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 设计 的 是 ， 由 一个 被 称为 的 人 ， 被 称为 的 ！'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = 'Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen'\n",
    "transformer.to(DEVICE)\n",
    "translate(transformer, src)\n",
    "#标准答案: A group of men are loading cotton onto a truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5315a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ce15f06e9c7630775e7e92434e446526d4a3f7c60a5439d34a99c99a0f9ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
